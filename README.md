# CodeLlama-7B-GGUF

https://github.com/VattamBhavaniPrasad5i5/CodeLlama-7B-GGUF/assets/97446586/40fc1959-b47c-4042-974c-989bea043963

 The Code Llama release introduces a family of models of 7, 13, and 34 billion parameters. The base models are initialized from Llama 2 and then trained on 500 billion tokens of code data. Meta fine-tuned those base models for two different flavors: a Python specialist (100 billion additional tokens) and an instruction fine-tuned version, which can understand natural language instructions.

The models show state-of-the-art performance in Python, C++, Java, PHP, C#, TypeScript, and Bash. The 7B and 13B base and instruct variants support infilling based on surrounding content, making them ideal for use as code assistants.

Code Llama was trained on a 16k context window. In addition, the three model variants had additional long-context fine-tuning, allowing them to manage a context window of up to 100,000 tokens.

Download codellama 7B instruct gguf here : https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF

You can download and based on your RAM specifications
